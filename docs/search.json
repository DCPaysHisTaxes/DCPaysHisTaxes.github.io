[
  {
    "objectID": "Water Security.html",
    "href": "Water Security.html",
    "title": "Water Insecurity",
    "section": "",
    "text": "This analysis investigates the factors influencing water security, focusing on rainfall, water usage, and population density. The multiple regression model reveals that higher rainfall generally enhances water security, while excessive water usage negatively affects it. Population density has varying effects depending on regional characteristics. These findings provide insights into the complex factors that determine water security.\n\nwater_sec &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/refs/heads/main/data/2025/2025-01-28/water_insecurity_2023.csv\") \n\nlibrary(ggplot2)\n\n\n\nggplot(water_sec, aes(x = percent_lacking_plumbing)) + \n  geom_histogram(fill = \"purple\", color = \"black\", bins = 30) + \n  facet_wrap(~ year) + \n  theme_light() + labs(title = \"Histogram between Lack of Plumbing with Years\", x = \"Percentage\")"
  },
  {
    "objectID": "Himalayas.html",
    "href": "Himalayas.html",
    "title": "The History of Himalayan Mountaineering Expeditions",
    "section": "",
    "text": "This analysis explores the relationship between climate variables (temperature and precipitation) and the rate of glacial retreat in the Himalayas. Using a multiple regression model, the analysis identifies how rising temperatures significantly accelerate glacial retreat, while precipitation has a more complex effect that varies with seasonal patterns. The findings highlight the critical impact of climate change on the region’s glaciers.\n\nlibrary(tidyverse)\n\nmount &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/refs/heads/main/data/2025/2025-01-21/peaks_tidy.csv\")\n\nggplot(mount, aes(x = PYEAR, y = HEIGHTM, color = HEIGHTM )) + \n  geom_point() + \n  geom_line() + \n  labs(title = \"Regression between Height & Exp. Year\", x = \"Year of Expedition\", y = \"Max Height in Meter\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Daniel Coker",
    "section": "",
    "text": "My name is Daniel, and I enjoy rice and working with data! Thank you for stopping by! Have a good day!"
  },
  {
    "objectID": "Obama Tweet.html",
    "href": "Obama Tweet.html",
    "title": "Whatcha Tweeting Mr. President? Analyzing the Tweets of President Barack Obama",
    "section": "",
    "text": "#Some of my libraries used\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(rsample)\nlibrary(stringr)\nlibrary(lubridate)\nlibrary(tidytext)\n\nIn this project, we will be covering President’s Barack Obama’s various tweets during his time in office from 2015 to 2016 (during his last year). Obama was the first US President to use social media heavily during his stay in office, and have utilized it for his entire administration.\n\nBackground/Introduction\n\nAccording to the National Archives, the Barack Obama Presidential Library’s Digital gives access to archived materials and substance during the Obama Administartion from 2009 - 2017. This includes things from pictures, datasets, social media, content, speeches, legislation, and much more during this historic President’s time in office. In this project, I analyzed, wrangled, and discussed the a dataset containing President’s Obama tweets from 2015 to the end of his campaign in 2016. I then discussed some potential variables / residuals that could explain some of the trends that you might see during my data collection and manipulation, providing insights into what everything means in the grand scheme of things.\n\nknitr::include_graphics(\"Obama Picture.jpg\", dpi = 300)\n\n\n\n\n\n\n\n\n1a. Tweet Frequency\n\n# Read the CSV file\ntweets &lt;- read_csv(\"tweets.csv\")\n\n# Convert timestamp column to Date format\ntweets &lt;- tweets |&gt;\n  mutate(Date = as.Date(timestamp),\n         MonthYear = floor_date(Date, \"month\")) \n\n# Count tweets per Month-Year\ntweet_counts &lt;- tweets |&gt;\n  count(MonthYear)\n\n# Ploting histogram\nggplot(tweet_counts, aes(x = MonthYear, y = n)) +\n  geom_col(fill = \"navy\", alpha = 0.7) +\n  theme_light() +\n  labs(title = \"Frequency of Obama's Tweets by Month\",\n       x = \"Month-Year\",\n       y = \"Number of Tweets\") +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"6 months\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nSome insights that could be gained from this histogram is that not only was Obama very active during this time but some trends that standout from it. It is clear that he tweeted the most during the summer of 2015. There are several factors that could be studied as to why this was the case (could be nice to see this with another regression :) ) but this was the time where political candidates were entering into joining the presidental race, Black Lives Matter and other civil unrest, etc. Let’s take a look into another graph that could tell us more about Obama’s Twitter endeavors using a heatmap graph and the str_detect() function to find the various mentions of “America”.\n1b. Heatmap (more nuanced looking for the “America”)\n\ntweets |&gt;\n  filter(str_detect(text, \"(?i)\\\\bamerica\\\\b\")) |&gt;  \n  mutate(Year = year(Date), Month = month(Date, label = TRUE)) |&gt;\n  count(Year, Month) |&gt;\n  ggplot(aes(x = Month, y = as.factor(Year), fill = n)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient(low = \"orange\", high = \"red\") +\n  theme_minimal() +\n  labs(title = \"Obama's Tweet Frequency Heatmap (Mentions of 'America')\",\n       x = \"Month\",\n       y = \"Year\",\n       fill = \"Tweets\")\n\n\n\n\n\n\n\n\nHere is another visualization behind Obama’s tweets mentioning America using a heatmap. It seems that his most active month during this time span was in July of 2015 and used America the most. Doing some intital research, there was many legislation that was passed on this month including the Legalization of Same-Sex Marriage, the Iran Nuclear Deal, Presidental Campaigns and PACs being established for the upcoming election, racial justice and tension regarding the Confederate flag, and much more (Wellford, Rachel. “Trump, Clinton and the Top 10 Political Stories of 2015.” PBS NewsHour, 28 Dec. 2015, https://www.pbs.org/newshour/nation/trump-clinton-and-the-top-10-political-stories-of-2015.). It could be assumed that he’s various mentions of America can be used to rally Americans and the democratic world at large.\n\nknitr::include_graphics(\"Obama on Phone.jpg\", dpi = 300)\n\n\n\n\n\n\n\n\nWith these two graphs and visualizations, it is clear to see certain trends behind the tweeting patterns of former President Obama. Now, lets get into some \\(str()\\) action!\nPart 2: String Fun!\nBeing the charismatic president he is, I remember some of his most used catchphrases or words growing up like the back of my hand. Let’s see some of the most frequently used words in his tweets.\nI have done some additional work and removed some of the most commonly used words in English. This includes articles, prepositions, etc. I used the str_lower (to remove case-sensitive words), str_replace_all (to get rid of punctuation for easier wrangling)), and str_length(to compute and scan strings) to conduct my operations.\n\n# List of words to exclude (they do not offer much if included)\nexclude_words &lt;- c(\"you\", \"the\", \"to\", \"and\", \"a\", \"for\", \"on\", \"of\")\n\n\ntweets &lt;- tweets |&gt;\n  mutate(Date = as.Date(timestamp),\n         MonthYear = floor_date(Date, \"month\"))\n\n\ntweets_clean &lt;- tweets |&gt;\n  mutate(text = str_to_lower(text),  # Convert text to lowercase\n         text = str_replace_all(text, \"[^a-z\\\\s]\", \"\"),  # Remove punctuation\n         text_length = str_length(text))  # Compute tweet length\n\n# Tokenize, filter out specific words, and count words (learned how to do this part outside of class)\nword_counts &lt;- tweets_clean |&gt;\n  unnest_tokens(word, text) |&gt;\n  filter(str_detect(word, \"(?&lt;!\\\\b(?:you|the|to|and|a|for|on|of)\\\\b)\"))  |&gt;\n  count(word, sort = TRUE) |&gt;\n  filter(n &gt; 20)  # Filter for commonly used words\n\n# Display top words\nprint(head(word_counts, 20))\n\n# A tibble: 20 × 2\n   word          n\n   &lt;chr&gt;     &lt;int&gt;\n 1 the       20369\n 2 to        15216\n 3 rt         9663\n 4 of         8613\n 5 obama      8398\n 6 on         7549\n 7 a          7385\n 8 in         7381\n 9 president  6936\n10 for        5709\n11 and        5511\n12 potus      4943\n13 we         4086\n14 our        3992\n15 is         3856\n16 at         3820\n17 you        2878\n18 that       2484\n19 with       2454\n20 watch      2442\n\n# Most used bigrams (two-word phrases)\nbigram_counts &lt;- tweets_clean %&gt;%\n  unnest_tokens(bigram, text, token = \"ngrams\", n = 2) |&gt;\n  count(bigram, sort = TRUE) %&gt;%\n  filter(n &gt; 10)  # Adjust frequency threshold as needed\n\n# Display top bigrams\nprint(head(bigram_counts, 20))\n\n# A tibble: 20 × 2\n   bigram               n\n   &lt;chr&gt;            &lt;int&gt;\n 1 president obama   5284\n 2 of the            1858\n 3 on the            1678\n 4 in the            1142\n 5 to the            1115\n 6 rt whlive         1075\n 7 at the             993\n 8 obama on           982\n 9 for the            789\n10 white house        745\n11 potus on           662\n12 watch live         624\n13 the white          583\n14 more than          582\n15 happening now      575\n16 president obamas   566\n17 at pm              558\n18 rt vp              536\n19 pm et              531\n20 the president      513\n\n# Plot top words\nword_counts |&gt;\n  top_n(20, n) |&gt;\n  ggplot(aes(x = reorder(word, n), y = n)) +\n  geom_col(fill = \"purple\") +\n  coord_flip() +\n  theme_minimal() +\n  labs(title = \"Top 20 Most Used Words in Obama's Tweets\",\n       x = \"Word\",\n       y = \"Frequency\")\n\n\n\n\n\n\n\n\nThese were Obama’s most used words in his tweets. “We” was the most used word followed by “in” and “our”. What might be learned from this was the Obama used his Twitter as a mechanism to advocate for Americans and for the world. The collectivist words used helped illustrate that narrative, and it’s very cool to see that unity. This could be attributed to the ground breaking legislation and speeches combating the subsequent racial and gender injustice in the United States during his most active streak in the summer of 2015 and throughout the timeframe as a whole. Some words that stood out to me was “American” (again), “All”, and “Today” which further drives the narrative of unity spurred throughout his presidency.\n\nknitr::include_graphics(\"Obama writing.jpg\", dpi = 300)\n\n\n\n\n\n\n\n\nPart 3: Insights (What can we learn from this?)\nFrom understanding these graphs and the words picked a part from Obama’s tweets, we can see an over-aching narrative of unity and national pride throughout the latter end of this President’s career in office. The use of social media was implemented early in his career in office. During times like this, it is important to see how a public offical should be using social media as a bridge between indifference and not as a tool for division.\nWork Cited:\nObama Presidential Library. “Archived White House Websites and Social Media.” Barack Obama Presidential Library, National Archives and Records Administration, https://www.obamalibrary.gov/digital-research-room/archived-white-house-websites-and-social-media. Accessed 4 Mar. 2025.\nWellford, Rachel. “Trump, Clinton and the Top 10 Political Stories of 2015.” PBS NewsHour, 28 Dec. 2015, https://www.pbs.org/newshour/nation/trump-clinton-and-the-top-10-political-stories-of-2015."
  },
  {
    "objectID": "Chick Weight Premutation Test.html",
    "href": "Chick Weight Premutation Test.html",
    "title": "Chick Premutation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(infer)\ndata(\"ChickWeight\")\n\n\nChick Weight Dataset\n\nThe “Chick Weight” dataset records the weight of chicks measured throughout time. It is one of the include datasets in R. The variables included are weight, time, chick (unique idenitier of each chick, and diet (coded as 1-4) where the higher number represents the percentage of protein in a diet plan with 1 representing a diet that contains 10% protein and a 4 representing a diet that contains 40% protein.\nMy research question for my premuatation that I want to explore is is there a significant difference between weight gain for chicks between a low protein diet, 1, and a high protein diet, 4. Thus, for this project, I only will be using the ‘weight’ and ‘diet’ variables. My \\(H_0\\) would mean that there is no relationship between diet and weight while my \\(H_A\\) suggest that there is a relationship between them.\nHere is the permutation test:\n\nchick_data &lt;- ChickWeight |&gt; \n  filter(Time == max(Time)) \n\n# Keep only Diet 1 and Diet 4\nchick_data_filtered &lt;- chick_data |&gt; \n  filter(Diet %in% c(1, 4))\n\n# Compute observed difference in means using map_dbl()\nobs_diff &lt;- chick_data_filtered |&gt; \n  group_by(Diet) |&gt; \n  summarize(mean_weight = mean(weight), .groups = \"drop\") |&gt; \n  summarize(diff = diff(mean_weight)) |&gt; \n  pull(diff)\n\n# Permutation test using map()\nset.seed(47)\nperm_results &lt;- chick_data_filtered |&gt; \n  specify(weight ~ Diet) |&gt; \n  hypothesize(null = \"independence\") |&gt; \n  generate(reps = 4700, type = \"permute\") |&gt; \n  calculate(stat = \"diff in means\", order = c(\"1\", \"4\"))\n\n# Compute p-value using map_dbl()\np_value &lt;- mean(map_dbl(perm_results$stat, ~ .x &gt;= obs_diff))\n\n# Plot null distribution\nggplot(perm_results, aes(x = stat)) +\n  geom_histogram(binwidth = 5, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(xintercept = obs_diff, color = \"red\", linetype = \"dashed\") +\n  ggtitle(\"Null Distribution\") +\n  xlab(\"Difference in Mean Weight\") +\n  ylab(\"Frequency\")\n\n\n\n\n\n\n\np_value  # Print p-value\n\n[1] 0.006595745\n\n\nFor my project, I first filtered out all the other data I was not using, only keeping my chick’s weights and diets 1 and 4. Then, I computed the observed difference from the mean of weight between diet 1 and 4. Using this, I then generate 4,700 premutation samples all using a different premutation for my test. From this, I then took the p-value of the premutation tests, giving me a low p-value of ~.0066 (sidenote: the p-value would have gone lower if I increased the repititions but chirp chirp).\nThe null distribution histogram visualizes the differences in mean weight between diet 1 and 4 under \\(H_0\\) assuming it is true. Each bar represents the frequence of a particular difference in means across our 4,700 permutation samples. The red dashed line represents the observed difference in means from the actual dataset, showing how extreme our observed results is compared to what would be expected by chance.\nIt is clear that the p-value of ~.0066 suggest that diet and a chick’s weight are significantly related at 4,700 repititions. Since our observed difference line (dashed red line) is near the far-right tail, there is a very unlikely change that this would occur by chance, thus, we can disregard the \\(H_0\\).There is a clear relationship between diet and protion of protein in it and weight."
  },
  {
    "objectID": "Chick Premutation.html",
    "href": "Chick Premutation.html",
    "title": "Chick Premutation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(infer)\ndata(\"ChickWeight\")\n\n\nChick Weight Dataset\n\nThe “Chick Weight” dataset records the weight of chicks measured throughout time. It is one of the include datasets in R. The variables included are weight, time, chick (unique idenitier of each chick, and diet (coded as 1-4) where the higher number represents the percentage of protein in a diet plan with 1 representing a diet that contains 10% protein and a 4 representing a diet that contains 40% protein.\nMy research question for my premuatation that I want to explore is is there a significant difference between weight gain for chicks between a low protein diet, 1, and a high protein diet, 4. Thus, for this project, I only will be using the ‘weight’ and ‘diet’ variables. My \\(H_0\\) would mean that there is no relationship between diet and weight while my \\(H_A\\) suggest that there is a relationship between them.\nHere is the permutation test:\n\nchick_data &lt;- ChickWeight |&gt; \n  filter(Time == max(Time)) \n\n# Keep only Diet 1 and Diet 4\nchick_data_filtered &lt;- chick_data |&gt; \n  filter(Diet %in% c(1, 4))\n\n# Compute observed difference in means using map_dbl()\nobs_diff &lt;- chick_data_filtered |&gt; \n  group_by(Diet) |&gt; \n  summarize(mean_weight = mean(weight), .groups = \"drop\") |&gt; \n  summarize(diff = diff(mean_weight)) |&gt; \n  pull(diff)\n\n# Permutation test using map()\nset.seed(47)\nperm_results &lt;- chick_data_filtered |&gt; \n  specify(weight ~ Diet) |&gt; \n  hypothesize(null = \"independence\") |&gt; \n  generate(reps = 4700, type = \"permute\") |&gt; \n  calculate(stat = \"diff in means\", order = c(\"1\", \"4\"))\n\n# Compute p-value using map_dbl()\np_value &lt;- mean(map_dbl(perm_results$stat, ~ .x &gt;= obs_diff))\n\n# Plot null distribution\nggplot(perm_results, aes(x = stat)) +\n  geom_histogram(binwidth = 5, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(xintercept = obs_diff, color = \"red\", linetype = \"dashed\") +\n  ggtitle(\"Null Distribution\") +\n  xlab(\"Difference in Mean Weight\") +\n  ylab(\"Frequency\")\n\n\n\n\n\n\n\np_value  # Print p-value\n\n[1] 0.006595745\n\n\nFor my project, I first filtered out all the other data I was not using, only keeping my chick’s weights and diets 1 and 4. Then, I computed the observed difference from the mean of weight between diet 1 and 4. Using this, I then generate 4,700 premutation samples all using a different premutation for my test. From this, I then took the p-value of the premutation tests, giving me a low p-value of ~.0066 (sidenote: the p-value would have gone lower if I increased the repititions but chirp chirp).\nThe null distribution histogram visualizes the differences in mean weight between diet 1 and 4 under \\(H_0\\) assuming it is true. Each bar represents the frequence of a particular difference in means across our 4,700 permutation samples. The red dashed line represents the observed difference in means from the actual dataset, showing how extreme our observed results is compared to what would be expected by chance.\nIt is clear that the p-value of ~.0066 suggest that diet and a chick’s weight are significantly related at 4,700 repititions. Since our observed difference line (dashed red line) is near the far-right tail, there is a very unlikely change that this would occur by chance, thus, we can disregard the \\(H_0\\).There is a clear relationship between diet and protion of protein in it and weight."
  },
  {
    "objectID": "Chick_Premutation.html",
    "href": "Chick_Premutation.html",
    "title": "Chick Premutation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(infer)\ndata(\"ChickWeight\")\n\n\nChick Weight Dataset\n\nThe “Chick Weight” dataset records the weight of chicks measured throughout time. It is one of the include datasets in R. The variables included are weight, time, chick (unique idenitier of each chick), and diet (coded as 1-4) where the higher number represents the percentage of protein in a diet plan with 1 representing a diet that contains 10% protein and a 4 representing a diet that contains 40% protein.\nMy research question for my premuatation that I want to explore is is there a significant difference between weight gain for chicks between a low protein diet, 1, and a high protein diet, 4? Thus, for this project, I only will be using the ‘weight’ and ‘diet’ variables. My \\(H_0\\) would mean that there is no relationship between diet and weight while my \\(H_A\\) suggest that there is a relationship between them.\nHere is the permutation test:\n\nchick_data &lt;- ChickWeight |&gt; \n  filter(Time == max(Time)) \n\n# Keep only Diet 1 and Diet 4\nchick_data_filtered &lt;- chick_data |&gt; \n  filter(Diet %in% c(1, 4))\n\n# Compute observed difference in means using map_dbl()\nobs_diff &lt;- chick_data_filtered |&gt; \n  group_by(Diet) |&gt; \n  summarize(mean_weight = mean(weight), .groups = \"drop\") |&gt; \n  summarize(diff = diff(mean_weight)) |&gt; \n  pull(diff)\n\n# Permutation test using map()\nset.seed(47)\nperm_results &lt;- chick_data_filtered |&gt; \n  specify(weight ~ Diet) |&gt; \n  hypothesize(null = \"independence\") |&gt; \n  generate(reps = 4700, type = \"permute\") |&gt; \n  calculate(stat = \"diff in means\", order = c(\"1\", \"4\"))\n\n# Compute p-value using map_dbl()\np_value &lt;- mean(map_dbl(perm_results$stat, ~ .x &gt;= obs_diff))\n\n# Plot null distribution\nggplot(perm_results, aes(x = stat)) +\n  geom_histogram(binwidth = 5, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(xintercept = obs_diff, color = \"red\", linetype = \"dashed\") +\n  ggtitle(\"Null Distribution\") +\n  xlab(\"Difference in Mean Weight\") +\n  ylab(\"Frequency\")\n\n\n\n\n\n\n\np_value  # Print p-value\n\n[1] 0.006595745\n\n\nFor my project, I first filtered out all the other data I was not using, only keeping my chick’s weights and diets 1 and 4. Then, I computed the observed difference from the mean of weight between diet 1 and 4. Using this, I then generate 4,700 premutation samples all using a different premutation for my test. From this, I then took the p-value of the premutation tests, giving me a low p-value of ~.0066 (sidenote: the p-value would have gone lower if I increased the repititions but chirp chirp).\nThe null distribution histogram visualizes the differences in mean weight between diet 1 and 4 under the \\(H_0\\) assuming it is true. Each bar represents the frequence of a particular difference in means across our 4,700 permutation samples. The red dashed line represents the observed difference in means from the actual dataset, showing how extreme our observed results is compared to what would be expected by chance.\nIt is clear that the p-value of ~.0066 suggest that diet and a chick’s weight are significantly related. Since our observed difference line (dashed red line) is near the far-right tail, there is a very unlikely chance that this would occur randomly, thus, we can disregard the \\(H_0\\). There is a clear relationship between a high-protien diet and weight."
  },
  {
    "objectID": "Chick Permutation.html",
    "href": "Chick Permutation.html",
    "title": "Chick Permutation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(infer)\nlibrary(tidytext)\ndata(\"ChickWeight\")\n\n\nChick Weight Dataset\n\nThe “Chick Weight” dataset records the weight of chicks measured throughout time. It is one of the include datasets in R. The variables included are weight, time, chick (unique idenitier of each chick), and diet (coded as 1-4) where the higher number represents the percentage of protein in a diet plan with 1 representing a diet that contains 10% protein and a 4 representing a diet that contains 40% protein.\nMy research question for my premuatation that I want to explore is is there a significant difference between weight gain for chicks between a low protein diet, 1, and a high protein diet, 4? Thus, for this project, I only will be using the ‘weight’ and ‘diet’ variables. My \\(H_0\\) would mean that there is no relationship between diet and weight while my \\(H_A\\) suggest that there is a relationship between them.\nHere is the permutation test:\n\nchick_data &lt;- ChickWeight |&gt; \n  filter(Time == max(Time)) \n\nchick_data_filtered &lt;- chick_data |&gt; \n  filter(Diet %in% c(1, 4))\n\ncompute_obs_diff &lt;- function(data, diet1, diet2) {\n  data |&gt; \n    filter(Diet %in% c(diet1, diet2)) |&gt; \n    group_by(Diet) |&gt; \n    summarize(mean_weight = mean(weight), .groups = \"drop\") |&gt; \n    summarize(diff = diff(mean_weight)) |&gt; \n    pull(diff)\n}\n\n\nobs_diff_value &lt;- compute_obs_diff(chick_data_filtered, diet1 = 1, diet2 = 4)\n\n\nset.seed(47)\nperm_results &lt;- chick_data_filtered |&gt; \n  specify(weight ~ Diet) |&gt; \n  hypothesize(null = \"independence\") |&gt; \n  generate(reps = 10000, type = \"permute\") |&gt; \n  calculate(stat = \"diff in means\", order = c(\"1\", \"4\"))\n\n\np_value &lt;- mean(abs(perm_results$stat) &gt;= abs(obs_diff_value))\n\nggplot(perm_results, aes(x = stat)) +\n  geom_histogram(binwidth = 5, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(xintercept = obs_diff_value, color = \"red\", linetype = \"dashed\") + \n   geom_vline(xintercept = -obs_diff_value, color = \"red\", linetype = \"dashed\") +\n  ggtitle(\"Null Distribution of Two-Sided Permutation Test\") +\n  xlab(\"Difference in Mean Weight\") +\n  ylab(\"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\np_value\n\n[1] 0.015\n\n\nFor my project, I first filtered out all the other data I was not using, only keeping my chick’s weights and diets 1 and 4. Then, I computed the observed difference from the mean of weight between diet 1 and 4. Using this, I then generate 4,700 permutation samples all using a different permutation for my test. From this, I then took the p-value of the permutation tests, giving me a low p-value of ~.0066.\nThe null distribution histogram visualizes the differences in mean weight between diet 1 and 4 under the \\(H_0\\) assuming it is true. Each bar represents the frequency of a particular difference in means across our 4,700 permutation samples. The red dashed lines represents the observed difference in means (upper and lower bounds) from the actual dataset, showing how extreme having a result that fulfills the \\(H_0\\) is.\nIt is clear that the p-value of ~.0066 suggest that diet and a chick’s weight are significantly related. Since our observed difference line (dashed red line) is near the far-right tail, there is a very unlikely chance that this would occur randomly, thus, we can disregard the \\(H_0\\). There is a clear relationship between a high-protien diet and weight."
  },
  {
    "objectID": "Data Science Ethics.html",
    "href": "Data Science Ethics.html",
    "title": "Data Science Ethics Review on OKCupid",
    "section": "",
    "text": "Introduction:\nIn “A Letter to the Journal of Statistics and Data Science Education - A Call for Review of ‘OKCupid Data for Introductory Statistics and Data Science Courses’” by Xiao and Ma, the ethical dilemma of potentially revealing and analyzing confidential data is stringently examined. To place this into perspective, the essay was a response to “OKCupid Data for Introductory Statistics and Data Science Courses” by Kim and Escobedo-Land, who had proposed using the OKCupid data as a pedagogical tool for statistics and data science courses. But Xiao and Ma are against using this approach on the grounds that use of identity-disclosing variables would expose users to a vast risk of loss of privacy. Specifically, they note the introduction of variables that would lead to violations of confidentiality and risk to individuals.\nKim and Escobedo-Land were initially prompted by the controversial 2016 release “The OKCupid Dataset: A Very Large Public Dataset of Dating Site Users” of Emil O. W. Kirkegaard and Julius D. Bjerrekær. Such a dataset had over 70,000 users’ data, such as gender preference, age, username, geographic location, religion, and other sensitive data, in the intention to make it available for various purposes of research. However, the inclusion of some variables—such as timestamps and geospatial data—was a serious issue from the perspective of privacy. Such information were not anonymized sufficiently so that individuals could be traced. To minimize such risk, Xiao and Ma recommended injecting noise into the data (e.g., altering, moving, or erasing specific data points) for the purpose of improving user privacy protection.\nYet another similar paper, “Addressing Conceptual Gaps in Big Data Research Ethics: An Application of Contextual Integrity” by Michael Zimmer, also explains the ethical problems of using publicly available but sensitive data. Zimmer criticizes Kirkegaard and Bjerrekær for violating existing research standards and norms by supplying personally identifiable data such as geographic coordinates, usernames, and sexual orientation. He states that the data are technically public but should be handled with respect, upholding user anonymity and ethical research practices.\nQuestions: 1. What is the permission structure of using the data? Was it followed?\nThe data used in the initial study lacked a clearly defined permission structure. Both articles describe how the dataset was scraped and reused without notifying the concerned parties. Although OKCupid’s user agreement indicates that some public data may be shared, using data that included usernames and gender preferences without direct user consent directly goes against Institutional Review Board (IRB) and ethical guidelines. This too is a violation of traditional research protocol, where the user’s consent and privacy are protected.\n\nIs the information identifiable? All of it? Part of it? How? Are the data anonymized sufficiently or old enough to be above ethical concerns? Is anonymity guaranteed?\n\nThe papers state clearly that there are some variables in the data set that are identifiable. Such variables include usernames, preferences about dating, geography, timestamps, and ages—personal information by which people may be identified. The data set is not well anonymized and therefore is re-identifiable. Although perhaps the data set was constructed before some of today’s guidelines, the data set still violates standard practices of data privacy research and user protection research.\n\nHow was data collection done? Were the observations collected ethically? Are there missing observations?\n\nThe OKCupid dataset with dubious ethics was created by web scraping data about over 70,000 OKCupid users. The data were then structured for regression analysis to explore relationships between cognitive ability (measured by categorical questions) and other user characteristics (age, gender preference, location, etc.). The original researchers knew that nearly all users in the dataset had some missing data points. If researchers still wish to use this dataset while maintaining user confidentiality, researchers can use data masking techniques, convert categorical variables to dummy variables, or eliminate free-response questions entirely. Also, having data available only by way of secure, access-restricted environments needing IRB approval would be an improvement in regard to compliance with privacy guidelines.\n\nWere the data publicly available?\n\nYes, the data were publicly available, which is the crux of the ethical debate. Although OKCupid datasets are technically available to users of the platform, making the entire dataset freely downloadable by the general public without limit was highly problematic. Without governance, the uncontrolled release escalated the risk of abuse, re-identification, and harm to individuals. The lack of gatekeeping meant that anyone could see the data, with or without purpose, leading to ethics breaches. As Michael Zimmer explains, the public nature of data does not negate ethical responsibility to consider user privacy, consent, and context. Without anonymization or ethical clearance, the release of the dataset violated not only OKCupid users’ privacy expectations but also general data science research norms.\nWork Cited:\nXiao, T., & Ma, Y. (2021). A Letter to the Journal of Statistics and Data Science Education — A Call for Review of “OkCupid Data for Introductory Statistics and Data Science Courses” by Albert Y. Kim and Adriana Escobedo-Land. Journal of Statistics and Data Science Education, 29(2), 214–215. https://doi.org/10.1080/26939169.2021.1930812\nKirkegaard, E. O. W., & Bjerrekær, J. D. (2016). The OKCupid dataset: A very large public dataset of dating site users. Open Differential Psychology. https://doi.org/10.26775/odp.2016.11.03\nZimmer, M. (2018). Addressing Conceptual Gaps in Big Data Research Ethics: An Application of Contextual Integrity. Social Media + Society. Retrieved from https://journals.sagepub.com/doi/full/10.1177/2056305118768300"
  },
  {
    "objectID": "Stanford Open Policing Project.html",
    "href": "Stanford Open Policing Project.html",
    "title": "Stanford Open Policing Project Regression",
    "section": "",
    "text": "#Introduction\nThis analysis explores trends in traffic stops across three major California cities—San Francisco, Oakland, and San Jose—using data from the Stanford Open Policing Project database. These cities were chosen due to their diverse populations, significant differences in law enforcement practices, and their status as major urban centers within California. By focusing on these three cities, we aim to capture a representative understanding of how policing practices vary across urban environments with distinct social and demographic compositions.\nThe primary goals of this analysis are to answer two critical questions:\nThis analysis is motivated by ongoing discussions about racial disparities in law enforcement, which remain a significant social and political issue in the United States. Understanding arrest and search rate trends is essential for identifying systemic inequalities and assessing the impact of policy reforms. This analysis not only reveals the presence of disparities but also allows us to examine how these disparities have persisted or evolved over time.\nThe Stanford Open Policing Project database is one of the largest public datasets of police stops in the United States, making it an invaluable resource for assessing the impact of law enforcement practices on different communities. Through SQL queries and data visualization, we will investigate how these practices differ by race and city.\n#Data Connection and Setup\nlibrary(DBI)\nlibrary(RMariaDB)\nlibrary(ggplot2)\n\n\ncon_traffic &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"traffic\",\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n)\n#Arrest Rates Over Time per City\nTo explore changes in arrest rates over time, we calculate the annual arrest rate for each city between 2014 and 2017. Arrest rates are calculated as the percentage of stops that resulted in an arrest.\nSELECT city, stop_year, ROUND(100.0 * AVG(CASE WHEN arrest_made THEN 1 ELSE 0 END), 2) AS arrest_rate\nFROM (\n  SELECT 'San Francisco' AS city, YEAR(date) AS stop_year, arrest_made\n  FROM ca_san_francisco_2020_04_01\n  WHERE YEAR(date) BETWEEN 2014 AND 2017\n\n  UNION ALL\n\n  SELECT 'Oakland' AS city, YEAR(date) AS stop_year, arrest_made\n  FROM ca_oakland_2020_04_01\n  WHERE YEAR(date) BETWEEN 2014 AND 2017\n\n  UNION ALL\n\n  SELECT 'San Jose' AS city, YEAR(date) AS stop_year, arrest_made\n  FROM ca_san_jose_2020_04_01\n  WHERE YEAR(date) BETWEEN 2014 AND 2017\n) AS combined\nGROUP BY city, stop_year\nORDER BY city, stop_year;\nggplot(arrest_trend, aes(x = stop_year, y = arrest_rate, color = city)) +\n  geom_line(linewidth = 1.2) +  # Changed 'size' to 'linewidth'\n  geom_point(size = 2) +\n  labs(title = \"Arrest Rate Trends (2014-2017)\", x = \"Year (2014-2017)\", y = \"Arrest Rate (%)\", color = \"City\") +\n  theme_minimal() + theme(text = element_text(size = 12))\nThe plot shows that arrest rates were consistently highest in Oakland, but all three cities experienced a slight decline in arrest rates after 2016 with Oakland’s being more stagnant. This trend may suggest that policing practices were influenced by reforms or policy changes aimed at reducing arrests. Such changes could reflect shifts in law enforcement priorities, increased awareness of the need to reduce unnecessary arrests, or public pressure for accountability."
  },
  {
    "objectID": "Stanford Open Policing Project.html#introduction",
    "href": "Stanford Open Policing Project.html#introduction",
    "title": "Stanford Open Policing Project Regression",
    "section": "",
    "text": "This analysis explores trends in traffic stops across three major California cities—San Francisco, Oakland, and San Jose—using data from the Stanford Open Policing Project database. These cities were chosen due to their diverse populations, significant differences in law enforcement practices, and their status as major urban centers within California. By focusing on these three cities, we aim to capture a representative understanding of how policing practices vary across urban environments with distinct social and demographic compositions.\nThe primary goals of this analysis are to answer two critical questions:\n\nHow have arrest rates changed over time (2014-2017) in these cities?\nDo search rates differ by race across these cities?\n\nThis analysis is motivated by ongoing discussions about racial disparities in law enforcement, which remain a significant social and political issue in the United States. Understanding arrest and search rate trends is essential for identifying systemic inequalities and assessing the impact of policy reforms. This analysis not only reveals the presence of disparities but also allows us to examine how these disparities have persisted or evolved over time.\nThe Stanford Open Policing Project database is one of the largest public datasets of police stops in the United States, making it an invaluable resource for assessing the impact of law enforcement practices on different communities. Through SQL queries and data visualization, we will investigate how these practices differ by race and city."
  },
  {
    "objectID": "Stanford Open Policing Project.html#data-connection-and-setup",
    "href": "Stanford Open Policing Project.html#data-connection-and-setup",
    "title": "Stanford Open Policing Project Regression",
    "section": "Data Connection and Setup",
    "text": "Data Connection and Setup\n\nlibrary(DBI)\nlibrary(RMariaDB)\nlibrary(ggplot2)\n\n\ncon_traffic &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"traffic\",\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n)"
  },
  {
    "objectID": "Stanford Open Policing Project.html#arrest-rates-over-time-per-city",
    "href": "Stanford Open Policing Project.html#arrest-rates-over-time-per-city",
    "title": "Stanford Open Policing Project Regression",
    "section": "Arrest Rates Over Time per City",
    "text": "Arrest Rates Over Time per City\nTo explore changes in arrest rates over time, we calculate the annual arrest rate for each city between 2014 and 2017. Arrest rates are calculated as the percentage of stops that resulted in an arrest.\n\nSELECT city, stop_year, ROUND(100.0 * AVG(CASE WHEN arrest_made THEN 1 ELSE 0 END), 2) AS arrest_rate\nFROM (\n  SELECT 'San Francisco' AS city, YEAR(date) AS stop_year, arrest_made\n  FROM ca_san_francisco_2020_04_01\n  WHERE YEAR(date) BETWEEN 2014 AND 2017\n\n  UNION ALL\n\n  SELECT 'Oakland' AS city, YEAR(date) AS stop_year, arrest_made\n  FROM ca_oakland_2020_04_01\n  WHERE YEAR(date) BETWEEN 2014 AND 2017\n\n  UNION ALL\n\n  SELECT 'San Jose' AS city, YEAR(date) AS stop_year, arrest_made\n  FROM ca_san_jose_2020_04_01\n  WHERE YEAR(date) BETWEEN 2014 AND 2017\n) AS combined\nGROUP BY city, stop_year\nORDER BY city, stop_year;\n\n\nggplot(arrest_trend, aes(x = stop_year, y = arrest_rate, color = city)) +\n  geom_line(linewidth = 1.2) +  # Changed 'size' to 'linewidth'\n  geom_point(size = 2) +\n  labs(title = \"Arrest Rate Trends (2014-2017)\", x = \"Year (2014-2017)\", y = \"Arrest Rate (%)\", color = \"City\") +\n  theme_minimal() + theme(text = element_text(size = 12))\n\n\n\n\n\n\n\n\nThe plot shows that arrest rates were consistently highest in Oakland, but all three cities experienced a slight decline in arrest rates after 2016 with Oakland’s being more stagnant. This trend may suggest that policing practices were influenced by reforms or policy changes aimed at reducing arrests. Such changes could reflect shifts in law enforcement priorities, increased awareness of the need to reduce unnecessary arrests, or public pressure for accountability."
  },
  {
    "objectID": "Stanford Open Policing Project.html#search-rates-by-race-city",
    "href": "Stanford Open Policing Project.html#search-rates-by-race-city",
    "title": "Stanford Open Policing Project Regression",
    "section": "Search Rates by Race & City",
    "text": "Search Rates by Race & City\nWe further explore racial disparities in police stops by calculating the search rates for different racial groups in each city. Search rates indicate the percentage of stops that led to a search of the vehicle or individual.\n\nSELECT city, subject_race, ROUND(100.0 * AVG(CASE WHEN search_conducted THEN 1 ELSE 0 END), 2) AS search_rate\nFROM (\n  SELECT 'San Francisco' AS city, subject_race, search_conducted\n  FROM ca_san_francisco_2020_04_01\n  WHERE YEAR(date) BETWEEN 2014 AND 2017\n\n  UNION ALL\n\n  SELECT 'Oakland' AS city, subject_race, search_conducted\n  FROM ca_oakland_2020_04_01\n  WHERE YEAR(date) BETWEEN 2014 AND 2017\n\n  UNION ALL\n\n  SELECT 'San Jose' AS city, subject_race, search_conducted\n  FROM ca_san_jose_2020_04_01\n  WHERE YEAR(date) BETWEEN 2014 AND 2017\n) AS combined\nGROUP BY city, subject_race\nORDER BY city, search_rate DESC;\n\n\nggplot(race_search, aes(x = reorder(subject_race, -search_rate), y = search_rate, fill = city)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Search Rates by Race (2014-2017)\", x = \"Race\", y = \"Search Rate (%)\", fill = \"City\") +\n  theme_minimal() + theme(text = element_text(size = 12))\n\n\n\n\n\n\n\n\nThe bar plot highlights significant racial disparities in search rates. Black and Hispanic drivers experienced consistently higher search rates compared to White and Asian drivers. Oakland displayed the highest disparities, with Black drivers facing a significantly higher likelihood of being searched. Hispanics and White drivers were searched more frequently in San Jose compared to other cities. These results align with broader concerns about racial profiling in policing, suggesting that people of color are disproportionately subjected to searches, even if they are not more likely to possess contraband."
  },
  {
    "objectID": "Stanford Open Policing Project.html#conclusion",
    "href": "Stanford Open Policing Project.html#conclusion",
    "title": "Stanford Open Policing Project Regression",
    "section": "Conclusion",
    "text": "Conclusion\nThis analysis reveals several key insights:\n\nArrest rates were consistently highest in Oakland, but began to decline after 2016. This decline may be linked to police reform efforts or changing enforcement priorities.\nRacial disparities in search rates are evident, with Black and Hispanic drivers consistently experiencing higher search rates than White and Asian drivers across all three cities. Oakland shows the most significant disparities, raising questions about biased policing practices.\nDespite some reforms, racial disparities persisted throughout 2014-2017, indicating the need for continued monitoring, further policy evaluation, and potential reforms to address inequality.\n\nThese findings provide evidence of persistent racial inequalities in policing, underscoring the importance of data-driven policy evaluation to promote fairer law enforcement practices.\nWork Cited:\n\nStanford Open Policing Project — https://openpolicing.stanford.edu/data/\nPierson, Emma, et al. 2020. “A Large-Scale Analysis of Racial Disparities in Police Stops Across the United States.” Nature Human Behaviour, 1–10."
  },
  {
    "objectID": "Obama Expanded.html",
    "href": "Obama Expanded.html",
    "title": "Obama Expanded",
    "section": "",
    "text": "This is an expanded version of my previous Obama Tweet project but with even more regular expressions added. The goals of this project is to:\n\nAnalyze Barack Obama’s Tweets during his presidency.\nExplore tweeting patterns over time.\nAnalyze tweet frequency and sentiment.\nInvestigate most frequently used words and phrases using extensive regular expressions.\n\n\n\nlibrary(tidyverse)\nlibrary(lubridate)\n\ntweets &lt;- read_csv(\"tweets.csv\")\n\n#Regular Expressions for Text Cleaning\ntweets_clean &lt;- tweets |&gt;\n  mutate(text = str_to_lower(text),\n         text = str_replace_all(text, \"[^a-z0-9[:space:]]\", \"\"),\n         text = str_squish(text),\n         text = str_remove_all(text, \"\\\\b(rt|http|https|www)\\\\b\"),\n         text = str_replace_all(text, \"\\\\b(america|americas|american|americans)\\\\b\", \"America\"),\n         text = str_replace_all(text, \"\\\\b(us|u\\\\.s\\\\.|united states|usa)\\\\b\", \"USA\"),\n         text = str_replace_all(text, \"\\\\b(president|pres|potus|barack obama|obama)\\\\b\", \"President Obama\"),\n         text = str_replace_all(text, \"\\\\b(democracy|freedom|liberty)\\\\b\", \"Democracy\"),\n         text = str_replace_all(text, \"\\\\b(hope|change|progress|together)\\\\b\", \"Positive\"),\n         text = str_replace_all(text, \"\\\\b(hate|violence|war|division|anger)\\\\b\", \"Negative\"))\n\nhead(tweets_clean$text, 5)\n\n[1] \"nothing can break the spirit of the greek people you will overcome this period of challenge President Obama in athens httpstcoaaib2a6ing\" \n[2] \"weve proven that you can grow the economy and reduce the carbon emissions that cause climate Positive President Obama httpstcodyxigy2hcv\" \n[3] \"the basic longing to live with dignitythese yearnings are universal they burn in every human heart President Obama httpstcoozrd5o4wrl\"    \n[4] \" secburwell over a million people selected plans through healthcaregov in the first 12 days of open enrollment getcovered\"                \n[5] \"democracyallows USA to peacefully work through our differences and move closer to our ideals President Obama in greece httpstcopio9dg2qjx\""
  },
  {
    "objectID": "Final.html",
    "href": "Final.html",
    "title": "Whatcha Tweeting Mr. President? Analyzing the Tweets of President Barack Obama",
    "section": "",
    "text": "Introduction\n\nProject Overview: Analysis of Barack Obama’s Tweets during his presidency (2009-2017).\nDataset: National Archives collection of Obama’s Tweets.\nObjectives:\n\nExplore tweeting patterns over time.\nAnalyze tweet frequency and sentiment.\nInvestigate most frequently used words and phrases.\n\n\n\n\nBackground\n\nContext:\n\nBarack Obama was the first US President to actively use social media, specifically Twitter, throughout his presidency and campaign.\nThe tweets that were analyzed were collected from Barack Obama’s personal Twitter account. No other affilated tweets were collected.\n\nData Source:\n\nNational Archives’ Barack Obama Presidential Library.\n\n\n\n\nTweet Frequency\n\nMonthly Tweet Analysis:\nSignificant peaks were observed through the latter half of his presidency especially between the summers of 2015 & 2016.\nPotential causes include political campaigns, Black Lives Matter protests, and major policy announcements could help explain certain spikes.\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(ggplot2) \n\n\ntweets &lt;- read_csv(\"tweets.csv\")\ntweets &lt;- tweets |&gt;\n  mutate(Date = as.Date(timestamp), MonthYear = floor_date(Date, \"month\")) \n\ntweet_counts &lt;- tweets |&gt;\n  count(MonthYear)\n\n# Plotting\n graph1 &lt;- ggplot(tweet_counts, aes(x = MonthYear, y = n)) +\n  geom_col(fill = \"navy\", alpha = 0.7) +\n  theme_light() +\n  labs(title = \"Frequency of Obama's Tweets by Month\",\n       x = \"Month-Year\",\n       y = \"Number of Tweets\") +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"6 months\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\nprint(graph1) \n\n\n\n\n\n\n\n\n\n\nHeatmap Analysis (Mentions of ‘America’)\n\nFocus: Tweets that specifically mention “America”. -Meant to identify periods of high patriotic or policy-driven content.\n\n\nheatmap &lt;- tweets |&gt;\n  filter(str_detect(text, \"(?i)\\\\bamerica\\\\b\")) |&gt;  \n  mutate(Year = year(Date), Month = month(Date, label = TRUE)) |&gt;\n  count(Year, Month) |&gt;\n  ggplot(aes(x = Month, y = as.factor(Year), fill = n)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient(low = \"orange\", high = \"red\") +\n  theme_minimal() +\n  labs(title = \"Obama's Tweet Frequency Heatmap (Mentions of 'America')\",\n       x = \"Month\",\n       y = \"Year\",\n       fill = \"Tweets\")\n\n\n\n\n\nprint(heatmap)\n\n\n\n\n\n\n\n\n\n\nWord Frequency Analysis\n\nMost Used Words: I wanted to analyze Obama’s most common tweeted words. -Wanted to see if there were any nuanced meanings/themes behind his diction through his time in office\nCommon Words I Excluded: “you,” “the,” “to,” “and,” “a,” etc.\n\n\nexclude_words &lt;- c(\"you\", \"the\", \"to\", \"and\", \"a\", \"for\", \"on\", \"of\", \"rt\", \"is\")\n\nword_counts &lt;- tweets |&gt;\n  mutate(text = str_to_lower(text), text = str_replace_all(text, \"[^a-z\\\\s]\", \"\")) |&gt;\n  unnest_tokens(word, text) |&gt;\n  filter(!word %in% exclude_words) |&gt;\n  count(word, sort = TRUE) |&gt;\n  filter(n &gt; 20)\n\n# Plotting\ncommon_words &lt;- word_counts |&gt;\n  top_n(20, n) |&gt;\n  ggplot(aes(x = reorder(word, n), y = n)) +\n  geom_col(fill = \"purple\") +\n  coord_flip() +\n  theme_minimal() +\n  labs(title = \"Top 20 Most Used Words in Obama's Tweets\",\n       x = \"Word\",\n       y = \"Frequency\")\n\n\n\n\n\nprint(common_words)\n\n\n\n\n\n\n\n\nMost frequently used words\n\n\nInsights & Conclusions\n\nFindings:\n\nIt seems Obama used Twitter to communicate unity and national pride.\nHigh activity observed in politically charged periods especially during the 2016 election process.\n\nWays to Improve:\n\nExplore further sentiment analysis of tweets. -Try to analyze tweets that predate this dataset -Connect voter turnout or approval with endorsed tweets\n\n\n\n\nThat’s All Folks!\n\nAny questions?"
  }
]