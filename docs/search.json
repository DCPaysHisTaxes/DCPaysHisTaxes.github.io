[
  {
    "objectID": "Water Security.html",
    "href": "Water Security.html",
    "title": "Water Insecurity",
    "section": "",
    "text": "water_sec &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/refs/heads/main/data/2025/2025-01-28/water_insecurity_2023.csv\") \n\nlibrary(ggplot2)\n\n\n\nggplot(water_sec, aes(x = percent_lacking_plumbing)) + \n  geom_histogram(fill = \"purple\", color = \"black\", bins = 30) + \n  facet_wrap(~ year) + \n  theme_light() + labs(title = \"Histogram between Lack of Plumbing with Years\", x = \"Percentage\")"
  },
  {
    "objectID": "Himalayas.html",
    "href": "Himalayas.html",
    "title": "The History of Himalayan Mountaineering Expeditions",
    "section": "",
    "text": "library(tidyverse)\n\nmount &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/refs/heads/main/data/2025/2025-01-21/peaks_tidy.csv\")\n\nggplot(mount, aes(x = PYEAR, y = HEIGHTM, color = HEIGHTM )) + \n  geom_point() + \n  geom_line() + \n  labs(title = \"Regression between Height & Exp. Year\", x = \"Year of Expedition\", y = \"Max Height in Meter\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Daniel Coker",
    "section": "",
    "text": "My name is Daniel, and I enjoy rice! Thank you for stopping by! Have a good day!!"
  },
  {
    "objectID": "Obama Tweet.html",
    "href": "Obama Tweet.html",
    "title": "Whatcha Tweeting Mr. President? Analyzing the Tweets of President Barack Obama",
    "section": "",
    "text": "#Some of my libraries used\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(rsample)\nlibrary(stringr)\nlibrary(lubridate)\nlibrary(tidytext)\n\nIn this project, we will be covering President’s Barack Obama’s various tweets during his time in office from 2015 to 2016 (during his last year). Obama was the first US President to use social media heavily during his stay in office, and have utilized it for his entire administration.\n\nBackground/Introduction\n\nAccording to the National Archives, the Barack Obama Presidential Library’s Digital gives access to archived materials and substance during the Obama Administartion from 2009 - 2017. This includes things from pictures, datasets, social media, content, speeches, legislation, and much more during this historic President’s time in office. In this project, I analyzed, wrangled, and discussed the a dataset containing President’s Obama tweets from 2015 to the end of his campaign in 2016. I then discussed some potential variables / residuals that could explain some of the trends that you might see during my data collection and manipulation, providing insights into what everything means in the grand scheme of things.\n\nknitr::include_graphics(\"Obama Picture.jpg\", dpi = 300)\n\n\n\n\n\n\n\n\n1a. Tweet Frequency\n\n# Read the CSV file\ntweets &lt;- read_csv(\"tweets.csv\")\n\n# Convert timestamp column to Date format\ntweets &lt;- tweets |&gt;\n  mutate(Date = as.Date(timestamp),\n         MonthYear = floor_date(Date, \"month\")) \n\n# Count tweets per Month-Year\ntweet_counts &lt;- tweets |&gt;\n  count(MonthYear)\n\n# Ploting histogram\nggplot(tweet_counts, aes(x = MonthYear, y = n)) +\n  geom_col(fill = \"navy\", alpha = 0.7) +\n  theme_light() +\n  labs(title = \"Frequency of Obama's Tweets by Month\",\n       x = \"Month-Year\",\n       y = \"Number of Tweets\") +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"6 months\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nSome insights that could be gained from this histogram is that not only was Obama very active during this time but some trends that standout from it. It is clear that he tweeted the most during the summer of 2015. There are several factors that could be studied as to why this was the case (could be nice to see this with another regression :) ) but this was the time where political candidates were entering into joining the presidental race, Black Lives Matter and other civil unrest, etc. Let’s take a look into another graph that could tell us more about Obama’s Twitter endeavors using a heatmap graph and the str_detect() function to find the various mentions of “America”.\n1b. Heatmap (more nuanced looking for the “America”)\n\ntweets |&gt;\n  filter(str_detect(text, \"(?i)\\\\bamerica\\\\b\")) |&gt;  \n  mutate(Year = year(Date), Month = month(Date, label = TRUE)) |&gt;\n  count(Year, Month) |&gt;\n  ggplot(aes(x = Month, y = as.factor(Year), fill = n)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient(low = \"orange\", high = \"red\") +\n  theme_minimal() +\n  labs(title = \"Obama's Tweet Frequency Heatmap (Mentions of 'America')\",\n       x = \"Month\",\n       y = \"Year\",\n       fill = \"Tweets\")\n\n\n\n\n\n\n\n\nHere is another visualization behind Obama’s tweets mentioning America using a heatmap. It seems that his most active month during this time span was in July of 2015 and used America the most. Doing some intital research, there was many legislation that was passed on this month including the Legalization of Same-Sex Marriage, the Iran Nuclear Deal, Presidental Campaigns and PACs being established for the upcoming election, racial justice and tension regarding the Confederate flag, and much more (Wellford, Rachel. “Trump, Clinton and the Top 10 Political Stories of 2015.” PBS NewsHour, 28 Dec. 2015, https://www.pbs.org/newshour/nation/trump-clinton-and-the-top-10-political-stories-of-2015.). It could be assumed that he’s various mentions of America can be used to rally Americans and the democratic world at large.\n\nknitr::include_graphics(\"Obama on Phone.jpg\", dpi = 300)\n\n\n\n\n\n\n\n\nWith these two graphs and visualizations, it is clear to see certain trends behind the tweeting patterns of former President Obama. Now, lets get into some \\(str()\\) action!\nPart 2: String Fun!\nBeing the charismatic president he is, I remember some of his most used catchphrases or words growing up like the back of my hand. Let’s see some of the most frequently used words in his tweets.\nI have done some additional work and removed some of the most commonly used words in English. This includes articles, prepositions, etc. I used the str_lower (to remove case-sensitive words), str_replace_all (to get rid of punctuation for easier wrangling)), and str_length(to compute and scan strings) to conduct my operations.\n\n# List of words to exclude (they do not offer much if included)\nexclude_words &lt;- c(\"you\", \"the\", \"to\", \"and\", \"a\", \"for\", \"on\", \"of\")\n\n\ntweets &lt;- tweets |&gt;\n  mutate(Date = as.Date(timestamp),\n         MonthYear = floor_date(Date, \"month\"))\n\n\ntweets_clean &lt;- tweets |&gt;\n  mutate(text = str_to_lower(text),  # Convert text to lowercase\n         text = str_replace_all(text, \"[^a-z\\\\s]\", \"\"),  # Remove punctuation\n         text_length = str_length(text))  # Compute tweet length\n\n# Tokenize, filter out specific words, and count words (learned how to do this part outside of class)\nword_counts &lt;- tweets_clean |&gt;\n  unnest_tokens(word, text) |&gt;\n  filter(str_detect(word, \"(?&lt;!\\\\b(?:you|the|to|and|a|for|on|of)\\\\b)\"))  |&gt;\n  count(word, sort = TRUE) |&gt;\n  filter(n &gt; 20)  # Filter for commonly used words\n\n# Display top words\nprint(head(word_counts, 20))\n\n# A tibble: 20 × 2\n   word      n\n   &lt;chr&gt; &lt;int&gt;\n 1 the     255\n 2 to      249\n 3 and     131\n 4 of      126\n 5 a       117\n 6 we       91\n 7 for      90\n 8 in       89\n 9 our      88\n10 on       60\n11 you      57\n12 with     44\n13 more     43\n14 it       42\n15 is       41\n16 this     41\n17 that     40\n18 can      38\n19 as       37\n20 i        35\n\n# Most used bigrams (two-word phrases)\nbigram_counts &lt;- tweets_clean %&gt;%\n  unnest_tokens(bigram, text, token = \"ngrams\", n = 2) |&gt;\n  count(bigram, sort = TRUE) %&gt;%\n  filter(n &gt; 10)  # Adjust frequency threshold as needed\n\n# Display top bigrams\nprint(head(bigram_counts, 20))\n\n# A tibble: 9 × 2\n  bigram             n\n  &lt;chr&gt;          &lt;int&gt;\n1 of the            21\n2 to the            19\n3 for the           16\n4 and the           15\n5 we can            14\n6 more than         13\n7 of our            12\n8 climate change    11\n9 in the            11\n\n# Plot top words\nword_counts |&gt;\n  top_n(20, n) |&gt;\n  ggplot(aes(x = reorder(word, n), y = n)) +\n  geom_col(fill = \"purple\") +\n  coord_flip() +\n  theme_minimal() +\n  labs(title = \"Top 20 Most Used Words in Obama's Tweets\",\n       x = \"Word\",\n       y = \"Frequency\")\n\n\n\n\n\n\n\n\nThese were Obama’s most used words in his tweets. “We” was the most used word followed by “in” and “our”. What might be learned from this was the Obama used his Twitter as a mechanism to advocate for Americans and for the world. The collectivist words used helped illustrate that narrative, and it’s very cool to see that unity. This could be attributed to the ground breaking legislation and speeches combating the subsequent racial and gender injustice in the United States during his most active streak in the summer of 2015 and throughout the timeframe as a whole. Some words that stood out to me was “American” (again), “All”, and “Today” which further drives the narrative of unity spurred throughout his presidency.\n\nknitr::include_graphics(\"Obama writing.jpg\", dpi = 300)\n\n\n\n\n\n\n\n\nPart 3: Insights (What can we learn from this?)\nFrom understanding these graphs and the words picked a part from Obama’s tweets, we can see an over-aching narrative of unity and national pride throughout the latter end of this President’s career in office. The use of social media was implemented early in his career in office. During times like this, it is important to see how a public offical should be using social media as a bridge between indifference and not as a tool for division.\nSOURCES:\nObama Presidential Library. “Archived White House Websites and Social Media.” Barack Obama Presidential Library, National Archives and Records Administration, https://www.obamalibrary.gov/digital-research-room/archived-white-house-websites-and-social-media. Accessed 4 Mar. 2025.\nWellford, Rachel. “Trump, Clinton and the Top 10 Political Stories of 2015.” PBS NewsHour, 28 Dec. 2015, https://www.pbs.org/newshour/nation/trump-clinton-and-the-top-10-political-stories-of-2015."
  },
  {
    "objectID": "Chick Weight Premutation Test.html",
    "href": "Chick Weight Premutation Test.html",
    "title": "Chick Premutation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(infer)\ndata(\"ChickWeight\")\n\n\nChick Weight Dataset\n\nThe “Chick Weight” dataset records the weight of chicks measured throughout time. It is one of the include datasets in R. The variables included are weight, time, chick (unique idenitier of each chick, and diet (coded as 1-4) where the higher number represents the percentage of protein in a diet plan with 1 representing a diet that contains 10% protein and a 4 representing a diet that contains 40% protein.\nMy research question for my premuatation that I want to explore is is there a significant difference between weight gain for chicks between a low protein diet, 1, and a high protein diet, 4. Thus, for this project, I only will be using the ‘weight’ and ‘diet’ variables. My \\(H_0\\) would mean that there is no relationship between diet and weight while my \\(H_A\\) suggest that there is a relationship between them.\nHere is the permutation test:\n\nchick_data &lt;- ChickWeight |&gt; \n  filter(Time == max(Time)) \n\n# Keep only Diet 1 and Diet 4\nchick_data_filtered &lt;- chick_data |&gt; \n  filter(Diet %in% c(1, 4))\n\n# Compute observed difference in means using map_dbl()\nobs_diff &lt;- chick_data_filtered |&gt; \n  group_by(Diet) |&gt; \n  summarize(mean_weight = mean(weight), .groups = \"drop\") |&gt; \n  summarize(diff = diff(mean_weight)) |&gt; \n  pull(diff)\n\n# Permutation test using map()\nset.seed(47)\nperm_results &lt;- chick_data_filtered |&gt; \n  specify(weight ~ Diet) |&gt; \n  hypothesize(null = \"independence\") |&gt; \n  generate(reps = 4700, type = \"permute\") |&gt; \n  calculate(stat = \"diff in means\", order = c(\"1\", \"4\"))\n\n# Compute p-value using map_dbl()\np_value &lt;- mean(map_dbl(perm_results$stat, ~ .x &gt;= obs_diff))\n\n# Plot null distribution\nggplot(perm_results, aes(x = stat)) +\n  geom_histogram(binwidth = 5, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(xintercept = obs_diff, color = \"red\", linetype = \"dashed\") +\n  ggtitle(\"Null Distribution\") +\n  xlab(\"Difference in Mean Weight\") +\n  ylab(\"Frequency\")\n\n\n\n\n\n\n\np_value  # Print p-value\n\n[1] 0.006595745\n\n\nFor my project, I first filtered out all the other data I was not using, only keeping my chick’s weights and diets 1 and 4. Then, I computed the observed difference from the mean of weight between diet 1 and 4. Using this, I then generate 4,700 premutation samples all using a different premutation for my test. From this, I then took the p-value of the premutation tests, giving me a low p-value of ~.0066 (sidenote: the p-value would have gone lower if I increased the repititions but chirp chirp).\nThe null distribution histogram visualizes the differences in mean weight between diet 1 and 4 under \\(H_0\\) assuming it is true. Each bar represents the frequence of a particular difference in means across our 4,700 permutation samples. The red dashed line represents the observed difference in means from the actual dataset, showing how extreme our observed results is compared to what would be expected by chance.\nIt is clear that the p-value of ~.0066 suggest that diet and a chick’s weight are significantly related at 4,700 repititions. Since our observed difference line (dashed red line) is near the far-right tail, there is a very unlikely change that this would occur by chance, thus, we can disregard the \\(H_0\\).There is a clear relationship between diet and protion of protein in it and weight."
  },
  {
    "objectID": "Chick Premutation.html",
    "href": "Chick Premutation.html",
    "title": "Chick Premutation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(infer)\ndata(\"ChickWeight\")\n\n\nChick Weight Dataset\n\nThe “Chick Weight” dataset records the weight of chicks measured throughout time. It is one of the include datasets in R. The variables included are weight, time, chick (unique idenitier of each chick, and diet (coded as 1-4) where the higher number represents the percentage of protein in a diet plan with 1 representing a diet that contains 10% protein and a 4 representing a diet that contains 40% protein.\nMy research question for my premuatation that I want to explore is is there a significant difference between weight gain for chicks between a low protein diet, 1, and a high protein diet, 4. Thus, for this project, I only will be using the ‘weight’ and ‘diet’ variables. My \\(H_0\\) would mean that there is no relationship between diet and weight while my \\(H_A\\) suggest that there is a relationship between them.\nHere is the permutation test:\n\nchick_data &lt;- ChickWeight |&gt; \n  filter(Time == max(Time)) \n\n# Keep only Diet 1 and Diet 4\nchick_data_filtered &lt;- chick_data |&gt; \n  filter(Diet %in% c(1, 4))\n\n# Compute observed difference in means using map_dbl()\nobs_diff &lt;- chick_data_filtered |&gt; \n  group_by(Diet) |&gt; \n  summarize(mean_weight = mean(weight), .groups = \"drop\") |&gt; \n  summarize(diff = diff(mean_weight)) |&gt; \n  pull(diff)\n\n# Permutation test using map()\nset.seed(47)\nperm_results &lt;- chick_data_filtered |&gt; \n  specify(weight ~ Diet) |&gt; \n  hypothesize(null = \"independence\") |&gt; \n  generate(reps = 4700, type = \"permute\") |&gt; \n  calculate(stat = \"diff in means\", order = c(\"1\", \"4\"))\n\n# Compute p-value using map_dbl()\np_value &lt;- mean(map_dbl(perm_results$stat, ~ .x &gt;= obs_diff))\n\n# Plot null distribution\nggplot(perm_results, aes(x = stat)) +\n  geom_histogram(binwidth = 5, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(xintercept = obs_diff, color = \"red\", linetype = \"dashed\") +\n  ggtitle(\"Null Distribution\") +\n  xlab(\"Difference in Mean Weight\") +\n  ylab(\"Frequency\")\n\n\n\n\n\n\n\np_value  # Print p-value\n\n[1] 0.006595745\n\n\nFor my project, I first filtered out all the other data I was not using, only keeping my chick’s weights and diets 1 and 4. Then, I computed the observed difference from the mean of weight between diet 1 and 4. Using this, I then generate 4,700 premutation samples all using a different premutation for my test. From this, I then took the p-value of the premutation tests, giving me a low p-value of ~.0066 (sidenote: the p-value would have gone lower if I increased the repititions but chirp chirp).\nThe null distribution histogram visualizes the differences in mean weight between diet 1 and 4 under \\(H_0\\) assuming it is true. Each bar represents the frequence of a particular difference in means across our 4,700 permutation samples. The red dashed line represents the observed difference in means from the actual dataset, showing how extreme our observed results is compared to what would be expected by chance.\nIt is clear that the p-value of ~.0066 suggest that diet and a chick’s weight are significantly related at 4,700 repititions. Since our observed difference line (dashed red line) is near the far-right tail, there is a very unlikely change that this would occur by chance, thus, we can disregard the \\(H_0\\).There is a clear relationship between diet and protion of protein in it and weight."
  },
  {
    "objectID": "Chick_Premutation.html",
    "href": "Chick_Premutation.html",
    "title": "Chick Premutation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(infer)\ndata(\"ChickWeight\")\n\n\nChick Weight Dataset\n\nThe “Chick Weight” dataset records the weight of chicks measured throughout time. It is one of the include datasets in R. The variables included are weight, time, chick (unique idenitier of each chick), and diet (coded as 1-4) where the higher number represents the percentage of protein in a diet plan with 1 representing a diet that contains 10% protein and a 4 representing a diet that contains 40% protein.\nMy research question for my premuatation that I want to explore is is there a significant difference between weight gain for chicks between a low protein diet, 1, and a high protein diet, 4? Thus, for this project, I only will be using the ‘weight’ and ‘diet’ variables. My \\(H_0\\) would mean that there is no relationship between diet and weight while my \\(H_A\\) suggest that there is a relationship between them.\nHere is the permutation test:\n\nchick_data &lt;- ChickWeight |&gt; \n  filter(Time == max(Time)) \n\n# Keep only Diet 1 and Diet 4\nchick_data_filtered &lt;- chick_data |&gt; \n  filter(Diet %in% c(1, 4))\n\n# Compute observed difference in means using map_dbl()\nobs_diff &lt;- chick_data_filtered |&gt; \n  group_by(Diet) |&gt; \n  summarize(mean_weight = mean(weight), .groups = \"drop\") |&gt; \n  summarize(diff = diff(mean_weight)) |&gt; \n  pull(diff)\n\n# Permutation test using map()\nset.seed(47)\nperm_results &lt;- chick_data_filtered |&gt; \n  specify(weight ~ Diet) |&gt; \n  hypothesize(null = \"independence\") |&gt; \n  generate(reps = 4700, type = \"permute\") |&gt; \n  calculate(stat = \"diff in means\", order = c(\"1\", \"4\"))\n\n# Compute p-value using map_dbl()\np_value &lt;- mean(map_dbl(perm_results$stat, ~ .x &gt;= obs_diff))\n\n# Plot null distribution\nggplot(perm_results, aes(x = stat)) +\n  geom_histogram(binwidth = 5, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(xintercept = obs_diff, color = \"red\", linetype = \"dashed\") +\n  ggtitle(\"Null Distribution\") +\n  xlab(\"Difference in Mean Weight\") +\n  ylab(\"Frequency\")\n\n\n\n\n\n\n\np_value  # Print p-value\n\n[1] 0.006595745\n\n\nFor my project, I first filtered out all the other data I was not using, only keeping my chick’s weights and diets 1 and 4. Then, I computed the observed difference from the mean of weight between diet 1 and 4. Using this, I then generate 4,700 premutation samples all using a different premutation for my test. From this, I then took the p-value of the premutation tests, giving me a low p-value of ~.0066 (sidenote: the p-value would have gone lower if I increased the repititions but chirp chirp).\nThe null distribution histogram visualizes the differences in mean weight between diet 1 and 4 under the \\(H_0\\) assuming it is true. Each bar represents the frequence of a particular difference in means across our 4,700 permutation samples. The red dashed line represents the observed difference in means from the actual dataset, showing how extreme our observed results is compared to what would be expected by chance.\nIt is clear that the p-value of ~.0066 suggest that diet and a chick’s weight are significantly related. Since our observed difference line (dashed red line) is near the far-right tail, there is a very unlikely chance that this would occur randomly, thus, we can disregard the \\(H_0\\). There is a clear relationship between a high-protien diet and weight."
  },
  {
    "objectID": "Chick Permutation.html",
    "href": "Chick Permutation.html",
    "title": "Chick Permutation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(infer)\ndata(\"ChickWeight\")\n\n\nChick Weight Dataset\n\nThe “Chick Weight” dataset records the weight of chicks measured throughout time. It is one of the include datasets in R. The variables included are weight, time, chick (unique idenitier of each chick), and diet (coded as 1-4) where the higher number represents the percentage of protein in a diet plan with 1 representing a diet that contains 10% protein and a 4 representing a diet that contains 40% protein.\nMy research question for my premuatation that I want to explore is is there a significant difference between weight gain for chicks between a low protein diet, 1, and a high protein diet, 4? Thus, for this project, I only will be using the ‘weight’ and ‘diet’ variables. My \\(H_0\\) would mean that there is no relationship between diet and weight while my \\(H_A\\) suggest that there is a relationship between them.\nHere is the permutation test:\n\nchick_data &lt;- ChickWeight |&gt; \n  filter(Time == max(Time)) \n\n#Keep only Diet 1 & 4\nchick_data_filtered &lt;- chick_data |&gt; \n  filter(Diet %in% c(1, 4))\n\n#Function to compute difference in means\ncompute_obs_diff &lt;- function(data, diet1, diet2) {\n  data |&gt; \n    filter(Diet %in% c(diet1, diet2)) |&gt; \n    group_by(Diet) |&gt; \n    summarize(mean_weight = mean(weight), .groups = \"drop\") |&gt; \n    summarize(diff = diff(mean_weight)) |&gt; \n    pull(diff)\n}\n\n#Compute observed difference in means\nobs_diff_value &lt;- compute_obs_diff(chick_data_filtered, diet1 = 1, diet2 = 4)\n\n#Permutation tet\nset.seed(47)\nperm_results &lt;- chick_data_filtered |&gt; \n  specify(weight ~ Diet) |&gt; \n  hypothesize(null = \"independence\") |&gt; \n  generate(reps = 10000, type = \"permute\") |&gt; \n  calculate(stat = \"diff in means\", order = c(\"1\", \"4\"))\n\np_value &lt;- mean(map_dbl(perm_results$stat, ~ .x &gt;= obs_diff_value))\n\n#Plot null distribution\nggplot(perm_results, aes(x = stat)) +\n  geom_histogram(binwidth = 5, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(xintercept = obs_diff_value, color = \"red\", linetype = \"dashed\") +\n  ggtitle(\"Null Distribution\") +\n  xlab(\"Difference in Mean Weight\") +\n  ylab(\"Frequency\")\n\n\n\n\n\n\n\np_value  \n\n[1] 0.0069\n\n\nFor my project, I first filtered out all the other data I was not using, only keeping my chick’s weights and diets 1 and 4. Then, I computed the observed difference from the mean of weight between diet 1 and 4. Using this, I then generate 4,700 permutation samples all using a different premutation for my test. From this, I then took the p-value of the premutation tests, giving me a low p-value of ~.0066 (sidenote: the p-value would have gone lower if I increased the repititions but chirp chirp).\nThe null distribution histogram visualizes the differences in mean weight between diet 1 and 4 under the \\(H_0\\) assuming it is true. Each bar represents the frequency of a particular difference in means across our 4,700 permutation samples. The red dashed line represents the observed difference in means from the actual dataset, showing how extreme having a result that fulfills the \\(H_0\\) is.\nIt is clear that the p-value of ~.0066 suggest that diet and a chick’s weight are significantly related. Since our observed difference line (dashed red line) is near the far-right tail, there is a very unlikely chance that this would occur randomly, thus, we can disregard the \\(H_0\\). There is a clear relationship between a high-protien diet and weight."
  },
  {
    "objectID": "Data Science Ethics.html",
    "href": "Data Science Ethics.html",
    "title": "Data Science Ethics",
    "section": "",
    "text": "References:\nXiao, T., & Ma, Y. (2021). A Letter to the Journal of Statistics and Data Science Education — A Call for Review of “OkCupid Data for Introductory Statistics and Data Science Courses” by Albert Y. Kim and Adriana Escobedo-Land. Journal of Statistics and Data Science Education, 29(2), 214–215. https://doi.org/10.1080/26939169.2021.1930812\nKirkegaard, E. O. W., & Bjerrekær, J. D. (2016). The OKCupid dataset: A very large public dataset of dating site users. Open Differential Psychology. https://doi.org/10.26775/odp.2016.11.03\nZimmer, M. (2018). Addressing Conceptual Gaps in Big Data Research Ethics: An Application of Contextual Integrity. Social Media + Society. Retrieved from https://journals.sagepub.com/doi/full/10.1177/2056305118768300\nIntroduction:\nIn the article “A Letter to the Journal of Statistics and Data Science Education - A call for Review of ‘OkCupid Data for Introductory Statistics and Data Science Courses’” by Xiao and Ma, the ethical dilemma of potentially revealing and analyzing confidental data is posed. For context, this article was writen in response to “OKCupid Data for Introductory Statistics and Data Science Courses” by Kim and Escobedo-Land where they aimed at using the OKCupid data as a teaching tool for data science and statistic coursers. However, Xiao and Ma criticize their notion as the use of identity revealing variables that could pose a confidental risk and harm inviduals. Kim and Escobedo-Land based their original writing off the controversy 2016 publication “The OKCupid dataset: A very large public dataset of dating site users” writen by Emil O. W. Kirkegaard and Julius D. Bjerrekær where they published over 70,000 users’ data which includes gender preferences, age, username, geographic location, religion, etc. with intentions of the dataset being used for various research proposes. One risk they addressed was certain variables including time and geopgraphic information about indivduals were included and not censored. This could potentially cause others’ privacy to feel encrouched. For intial solutions, they propose introducing noise (which in this case would be changing, moving, or removing words) to better secure people’s information within the dataset and study as a whole.\nAnother correlate article, “Addressing Conceptual Gaps in Big Data Research Ethics: An Application of Contextual Integrity” by Michael Zimmer also tackles the dilemna of “public” sensitive data being available for research and for the masses. He criticizes Kirkegaard and Bjerrekær stating they violated not only established research norms but also guidelines surrounding online dating by including variables such as geographic location, usernames, and even gender preference in their intial dataset. Likewise with Xiao and Ma, he further emphasizes and stresses that not censoring these and other related variables would have convey personal information. This article discusses more on the unethical research review that the OKCupid dataset violates.\nQuestions:\n\nWhat is the permission structure of using the data? Was it followed?\n\nThe data used in the initial study lacked a clear permission structure. Both articles describe how the dataset was scraped and repurposed without noticing the individuals involved. OKCupid does include in their user agreements that some public info would be shared; however, using the data which included usernames and gender-preference without checking with inviduals to see if it okay goes against the IRB and legislation guidelines and breaks traditional research norms.\n\nIs the data identifiable? All of it? Some of it? In what way? Are the data sufficiently anonymized or old to be free of ethical concerns? Is anonymity guaranteed?\n\nIt is clearly stated between the two articles that some data and variable were idenitifiable. Variables including usernames, dating preferences, geographic location, time, and age were all made available to the public. It seems that there was little or no sufficient anoymizatio efforts that took place when constructing the data. While the dataset might’ve been constructed before new guidelines, it still goes against many research norms.\n3.What was the data collection process? Were the observations collected ethically? Are there missing observations?\nThe main OKCupid dataset that caused a lot of these issues took over 70,000 OkCupid users data from OkCupid and scrubbed the data to be used for regressional uses like checking cognitive ability through categorical questions asked by OKCupid in relation to other variables (age, gender-preference, location, etc.) in the constructed dataset. The intial researhers of the dataset stated that almost every user in the dataset had some missing data/observation too. I would like to add that if other researchers still wanted to use this dataset but maintain confidentiality, then they could definitely implemented some data masking, make the categorical variables into dummy variables, or just remove the free response questions all together. Additionally, researchers could release the data only through secure, access-controlled environments that require Institutional Review Board (IRB) approval or equivalent oversight to ensure their analysis followed approved privacy guidelines.\n\nWere the data made publicly available?\n\nThe data was, in fact, made public, hence the intial controversy surrounding its release. The exposure of all of these users’ data, even if OKCupid’s datasets are open, it still shouldn’t have been made public without further oversight."
  }
]